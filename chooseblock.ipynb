{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得直接用于lora的专家数量\n",
    "#分开取\n",
    "import json\n",
    "import numpy as np\n",
    "dataset = ['boolq', 'piqa','social_i_qa','winogrande','ARC-Easy','ARC-Challenge','openbookqa','hellaswag']\n",
    "qkvo = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "OUTDATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/sentisive/senti_7b_fenkai.json'     \n",
    "nameexpertnum = {}\n",
    "percentile = 60\n",
    "for GG in range(8):\n",
    "    DATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/dataset/'+dataset[GG]+'/T7bBexpert.json'\n",
    "    all_list = []\n",
    "    for i in range(7):\n",
    "        all_list.append([])\n",
    "    indexnum = 0 \n",
    "    with open(DATAPATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            indexnum = indexnum%7\n",
    "            # 解析每一行 JSON 对象\n",
    "            json_obj = json.loads(line)\n",
    "            # 将解析后的键值对添加到列表中\n",
    "            all_list[indexnum].append(json_obj)\n",
    "            indexnum +=1\n",
    "    \n",
    "    # sorted_qkvo_data = sorted(qkvo_list, key=lambda x: list(x.values())[0], reverse=True)\n",
    "    # 获得阈值\n",
    "    all_threshold = []\n",
    "    for i in range(7):\n",
    "        threshold  = np.percentile(\n",
    "        [list(item.values())[0] for item in all_list[i]], \n",
    "        100-percentile\n",
    ")\n",
    "        all_threshold.append(threshold)\n",
    "    \n",
    "    with open(DATAPATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            indexnum = indexnum%7\n",
    "            # 解析每一行 JSON 对象\n",
    "            json_obj = json.loads(line)\n",
    "            # 将解析后的键值对添加到列表中\n",
    "            if list(json_obj.values())[0]>all_threshold[indexnum]:\n",
    "                name = list(json_obj.keys())[0]\n",
    "                if name in nameexpertnum:\n",
    "                    nameexpertnum[name]+=1\n",
    "                else :\n",
    "                    nameexpertnum[name]=1   \n",
    "            indexnum +=1\n",
    "       \n",
    "filtered_data = {k.replace('.weight', ''): v for k, v in nameexpertnum.items() if k.endswith('.weight')}\n",
    "with open(OUTDATAPATH, 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复现高层需要更多专家\n",
    "import json\n",
    "import numpy as np\n",
    "dataset = ['boolq', 'piqa','social_i_qa','winogrande','ARC-Easy','ARC-Challenge','openbookqa','hellaswag']\n",
    "qkvo = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "OUTDATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/sentisive/H8642_7b.json'     \n",
    "nameexpertnum = {}\n",
    "percentile = 40\n",
    "for GG in range(1):\n",
    "    DATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/dataset/'+dataset[GG]+'/T7bBexpert.json'\n",
    "    indexnum =0\n",
    "    with open(DATAPATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            # 解析每一行 JSON 对象\n",
    "            json_obj = json.loads(line)\n",
    "            # 将解析后的键值对添加到列表中\n",
    "            name = list(json_obj.keys())[0]\n",
    "            if indexnum <48:\n",
    "                nameexpertnum[name]=2\n",
    "            elif indexnum <97:\n",
    "                nameexpertnum[name]=4\n",
    "            elif indexnum <147:\n",
    "                nameexpertnum[name]=6\n",
    "            else:\n",
    "                nameexpertnum[name]=8\n",
    "            indexnum +=1\n",
    "       \n",
    "filtered_data = {k.replace('.weight', ''): v for k, v in nameexpertnum.items() if k.endswith('.weight')}\n",
    "with open(OUTDATAPATH, 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得直接用于lora的专家数量\n",
    "#\n",
    "import json\n",
    "import numpy as np\n",
    "dataset = ['boolq', 'piqa','social_i_qa','winogrande','ARC-Easy','ARC-Challenge','openbookqa','hellaswag']\n",
    "qkvo = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "OUTDATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/sentisive/3bqkvomlpall60.json'     \n",
    "nameexpertnum = {}\n",
    "percentile = 40\n",
    "for GG in range(8):\n",
    "    DATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/dataset/'+dataset[GG]+'/train.jsonexpert3b.json'\n",
    "    all_list = []\n",
    "    indexnum = 0 \n",
    "    with open(DATAPATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            indexnum = indexnum%7\n",
    "            # 解析每一行 JSON 对象\n",
    "            if indexnum<7:\n",
    "                json_obj = json.loads(line)\n",
    "            # 将解析后的键值对添加到列表中\n",
    "                all_list.append(json_obj)\n",
    "            indexnum +=1\n",
    "            \n",
    "\n",
    "\n",
    "    threshold  = np.percentile(\n",
    "        [list(item.values())[0] for item in all_list], \n",
    "        percentile\n",
    ")\n",
    "    \n",
    "    with open(DATAPATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            indexnum = indexnum%7\n",
    "            # 解析每一行 JSON 对象\n",
    "            if indexnum<7:\n",
    "                json_obj = json.loads(line)\n",
    "                # 将解析后的键值对添加到列表中\n",
    "                if list(json_obj.values())[0]>threshold:\n",
    "                    name = list(json_obj.keys())[0]\n",
    "                    if name in nameexpertnum:\n",
    "                        nameexpertnum[name]+=1\n",
    "                    else :\n",
    "                        nameexpertnum[name]=1   \n",
    "            indexnum +=1\n",
    "       \n",
    "filtered_data = {k.replace('.weight', ''): v for k, v in nameexpertnum.items() if k.endswith('.weight')}\n",
    "with open(OUTDATAPATH, 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得直接用于lora的专家数量\n",
    "# qkvo mlp分成两部分计算\n",
    "import json\n",
    "import numpy as np\n",
    "dataset = ['boolq', 'piqa','social_i_qa','winogrande','ARC-Easy','ARC-Challenge','openbookqa','hellaswag']\n",
    "qkvo = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "OUTDATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/sentisive/att_mlp_7b.json'     \n",
    "nameexpertnum = {}\n",
    "percentile = 60\n",
    "for GG in range(8):\n",
    "    DATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/dataset/'+dataset[GG]+'/T7bBexpert.json'\n",
    "    \n",
    "    qkvo_list = []\n",
    "    mlp_list = []\n",
    "    indexnum = 0 \n",
    "    with open(DATAPATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            \n",
    "            # 解析每一行 JSON 对象\n",
    "            json_obj = json.loads(line)\n",
    "            # 将解析后的键值对添加到列表中\n",
    "            if indexnum%7<4:\n",
    "                qkvo_list.append(json_obj)\n",
    "            else:\n",
    "                mlp_list.append(json_obj)\n",
    "            indexnum +=1\n",
    "    sorted_qkvo_data = sorted(qkvo_list, key=lambda x: list(x.values())[0], reverse=True)\n",
    "    sorted_mlp_data = sorted(mlp_list, key=lambda x: list(x.values())[0], reverse=True)\n",
    "    # 获得阈值\n",
    "    qkvo_threshold  = np.percentile(\n",
    "    [list(item.values())[0] for item in sorted_qkvo_data], \n",
    "    100-percentile\n",
    ")\n",
    "    mlp_threshold  = np.percentile(\n",
    "    [list(item.values())[0] for item in sorted_mlp_data], \n",
    "    100-percentile\n",
    ")\n",
    "    \n",
    "    for i in range(len(sorted_qkvo_data)):\n",
    "        if list(sorted_qkvo_data[i].values())[0] >qkvo_threshold:\n",
    "            name = list(sorted_qkvo_data[i].keys())[0]\n",
    "            if name in nameexpertnum:\n",
    "                nameexpertnum[name]+=1\n",
    "            else :\n",
    "                nameexpertnum[name]=1\n",
    "\n",
    "    # for i in range(len(sorted_mlp_data)):\n",
    "    #     if list(sorted_mlp_data[i].values())[0] >mlp_threshold:\n",
    "    #         name = list(sorted_mlp_data[i].keys())[0]\n",
    "    #         if name in nameexpertnum:\n",
    "    #             nameexpertnum[name]+=1\n",
    "    #         else :\n",
    "    #             nameexpertnum[name]=1\n",
    "filtered_data = {k.replace('.weight', ''): v for k, v in nameexpertnum.items() if k.endswith('.weight')}\n",
    "with open(OUTDATAPATH, 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除weight\n",
    "import json\n",
    "test = '/home/xjz/proj/Subspace-Tuning/CR_MR/sentisive/3b50qkvomlp.json'\n",
    "data = []\n",
    "with open(test, 'r', encoding='utf-8') as file:\n",
    "    # 使用 json.load() 方法将文件内容解析为 Python 字典\n",
    "    data = json.load(file)\n",
    "    \n",
    "    # Filter out keys containing '.weight'\n",
    "    filtered_data = {k.replace('.weight', ''): v for k, v in data.items() if k.endswith('.weight')}\n",
    "\n",
    "# Save the filtered data back to a JSON file\n",
    "with open('/home/xjz/proj/Subspace-Tuning/CR_MR/sentisive/3b50qkvomlpnoweight.json', 'w') as file:\n",
    "    json.dump(filtered_data, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905472636815921\n",
      "0.8656716417910447\n",
      "0.8557213930348259\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 不同训练集对于敏感性值的影响\n",
    "def numpy_min_max_normalize(data):\n",
    "    \"\"\"使用numpy对一维数组执行最小-最大归一化\"\"\"\n",
    "    data = np.array(data, dtype=float)\n",
    "    data_min = data.min()\n",
    "    data_max = data.max()\n",
    "    \n",
    "    # 避免除以零的情况\n",
    "    if data_max == data_min:\n",
    "        return np.full_like(data, 0.5)  # 如果所有值相同，返回一个全为0.5的数组\n",
    "    \n",
    "    # 归一化计算\n",
    "    normalized_data = (data - data_min) / (data_max - data_min)\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "def find_proj_index(input_str):\n",
    "    # 定义映射关系\n",
    "    init_ste = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\",\"gate_proj\"]\n",
    "    mapping = {proj: idx for idx, proj in enumerate(init_ste)}\n",
    "\n",
    "    # 检查输入字符串是否包含任意一个子串，并返回对应的索引\n",
    "    for proj, index in mapping.items():\n",
    "        if proj in input_str:\n",
    "            return index\n",
    "\n",
    "    # 如果没有任何匹配，返回-1或None或其他你认为合适的值\n",
    "    return -1  # 或者 return None\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "layer_block_Senti = np.zeros((4,36, 7), dtype=float)\n",
    "threshold = np.zeros((4,2),dtype=float)\n",
    "num_index = ['36','72','144','288']\n",
    "for GG in range(4):\n",
    "    layer_block_Senti[GG] = np.zeros((36, 7), dtype=float)\n",
    "    dataset = ['boolq', 'piqa','social_i_qa','winogrande','ARC-Easy','ARC-Challenge','openbookqa','hellaswag']\n",
    "    DATAPATH = r'/home/xjz/proj/Subspace-Tuning/CR_MR/dataset/ARC-Easy/T3B_SENTI_'+num_index[GG]+'.json'\n",
    "   \n",
    "    \n",
    "    with open(DATAPATH, 'r') as f:\n",
    "    # 使用 json.load() 方法将文件内容解析为 Python 字典\n",
    "        # 此处结构不一样\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "\n",
    "            json_obj = json.loads(line)\n",
    "            key = list(json_obj)[0]\n",
    "\n",
    "            int_pattern = r'-?\\b\\d+\\b'\n",
    "            layer_num = re.search(int_pattern, key)\n",
    "            layer_num=int(layer_num.group())\n",
    "            \n",
    "            block_num = find_proj_index(key)\n",
    "            layer_block_Senti[GG][layer_num][block_num] = json_obj[key]\n",
    "        layer_block = layer_block_Senti[GG]\n",
    "        mean_values = np.mean(layer_block, axis=0)\n",
    "        variance_values = np.var(layer_block, axis=0)\n",
    "        \n",
    "        \n",
    "        threshold[GG][0]  = np.percentile( layer_block_Senti[GG][:,:4], \n",
    "    20\n",
    ")\n",
    "        threshold[GG][1]  = np.percentile(layer_block_Senti[GG][:,4:], \n",
    "    20\n",
    ")\n",
    "        \n",
    "        \n",
    "        # print('GG')\n",
    "        # print(mean_values)\n",
    "        # print(variance_values)\n",
    "for i in range(4):\n",
    "        layer_block_Senti[i][:,:4] = np.where(layer_block_Senti[i][:,:4]>threshold[i][0],1,0 )\n",
    "        layer_block_Senti[i][:,4:] = np.where(layer_block_Senti[i][:,4:]>threshold[i][1],1,0 )\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "  both_ones = np.logical_and(layer_block_Senti[i] == 1, layer_block_Senti[3] == 1)\n",
    "  both_ones = np.sum(both_ones) \n",
    "  total_ones = np.sum(layer_block_Senti[i] == 1)\n",
    "  print(both_ones/total_ones)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import Normalize\n",
    "\n",
    "# matrix_labels = ['q', 'k', 'v', 'o', 'up', 'down','gate']\n",
    "\n",
    "# fig, axes = plt.subplots(1, 5, figsize=(15, 8))\n",
    "# axes = axes.ravel()  # 将二维数组拉平为一维以简化循环\n",
    "# # 定义两个颜色映射\n",
    "# cmap_part1 = \"Reds\"  # 第一部分的颜色映射\n",
    "# cmap_part2 = \"Blues\"  # 第二部分的颜色映射\n",
    "# # 循环遍历每一组数据并绘制对应的热力图\n",
    "# for idx, ax in enumerate(axes):\n",
    "#     # 获取当前子图的数据和最大值用于后面设定 vmax 参数\n",
    "#     data = layer_block_Senti[idx]\n",
    "#     data_max = np.max(data)\n",
    "    \n",
    "#     # 设定 vmax 参数以抑制最大值的颜色显示，这里我们取最大值的95%作为 vmax\n",
    "#     vmax_value = np.percentile(data, 95)\n",
    "#     mask_part1 = np.zeros_like(data, dtype=bool)  # 假设前半部分使用红色\n",
    "#     mask_part2 = np.ones_like(data, dtype=bool)   # 后半部分使用蓝色\n",
    "    \n",
    "#     mask_part1[:, :4] = True\n",
    "#     mask_part2[:, :4] = False\n",
    "    \n",
    "#     data_part1 = np.ma.masked_array(data, mask=~mask_part1)\n",
    "#     data_part2 = np.ma.masked_array(data, mask=~mask_part2)\n",
    "   \n",
    "    \n",
    "#     vmin_part1, vmax_part1 = data_part1.min(), data_part1.max()\n",
    "#     vmin_part2, vmax_part2 = data_part2.min(), data_part2.max()\n",
    "#     data1 = data[:, :4]\n",
    "#     data2 = data[:, 4:]\n",
    "\n",
    "#     median_part1 = np.median(data1)\n",
    "#     median_part2 = np.median(data2)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     threshold = 0.5 \n",
    "#     mask = data > threshold\n",
    "#     y_indices, x_indices = np.where(mask)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.scatter(x_indices, y_indices, c='red', marker='s') \n",
    "#     sns.heatmap(data, cmap=cmap_part1, linewidths=.5, xticklabels=matrix_labels, ax=ax,\n",
    "#                 norm=Normalize(vmin=0.05, vmax=vmax_part1*0.7), cbar=False, mask=~mask_part1)\n",
    "    \n",
    "#     # 绘制第二部分热力图\n",
    "#     sns.heatmap(data, cmap=cmap_part2, linewidths=.5, xticklabels=matrix_labels, ax=ax,\n",
    "#                 norm=Normalize(vmin=0.05, vmax=vmax_part2*0.7), cbar=False, mask=~mask_part2)\n",
    "   \n",
    "#     # 设置标题和标签\n",
    "#     # ax.set_title(f'{dataset[idx]}')  # 给每个子图添加标题\n",
    "#     # ax.set_xlabel('Matrices')\n",
    "#     ax.set_ylabel('Layers') if idx % 4 == 0 else None  # 只给左侧的子图添加y轴标签\n",
    "\n",
    "#     # 反转y轴\n",
    "#     ax.invert_yaxis()\n",
    "\n",
    "#     # 旋转x轴标签以适应布局（可选）\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# # 调整子图之间的间距\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # 显示图形\n",
    "# plt.show()\n",
    "           \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
